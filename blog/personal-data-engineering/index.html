<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en-us lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><base href=https://zmsy.github.io/zmsy.co/><title>zmsy | An Architecture For Personal Data Engineering</title><meta name=og:title content="An Architecture For Personal Data Engineering"><meta name=description content="There's a lot of data that I use in my life that would benefit from some infrastructure work. Here's hoping to create something that makes this easier for me."><meta name=og:description content="There's a lot of data that I use in my life that would benefit from some infrastructure work. Here's hoping to create something that makes this easier for me."><link rel=stylesheet href=https://zmsy.github.io/zmsy.co/css/main.css><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css><link href="https://fonts.googleapis.com/css?family=Patua+One|Work+Sans&display=swap" rel=stylesheet><link rel=icon type=image/png href=https://zmsy.github.io/zmsy.co/media/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=https://zmsy.github.io/zmsy.co/media/favicon-16x16.png sizes=16x16><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/zmsy.github.io\/zmsy.co\/"},"name":"An Architecture For Personal Data Engineering","headline":"An Architecture For Personal Data Engineering","description":"There\u0027s a lot of data that I use in my life that would benefit from some infrastructure work. Here\u0027s hoping to create something that makes this easier for me.","inLanguage":"en-US","author":"Zach Morrissey","creator":"Zach Morrissey","publisher":"Zach Morrissey","accountablePerson":"Zach Morrissey","copyrightHolder":"Zach Morrissey","copyrightYear":"2021","datePublished":"2018-01-31","dateModified":"2021-03-08T06:04:30Z","url":"https:\/\/zmsy.github.io\/zmsy.co\/blog\/personal-data-engineering\/","keywords":["Blog"]}</script></head><body><div class="columns is-centered" id=navbar-columns><div class="column is-10 is-12-touch" id=navbar-column><nav class=navbar role=navigation id=top><div class=navbar-brand><a class=navbar-item href=https://zmsy.github.io/zmsy.co/><img id=logo-img src=https://zmsy.github.io/zmsy.co/media/logo.svg alt="zmsy.co - Home"></a>
<a class=navbar-item href=https://zmsy.github.io/zmsy.co/><div class=is-3 id=logo-text>zmsy.co</div></a><span class=navbar-burger id=navbar-toggle><span></span><span></span><span></span></span></div><div class=navbar-menu><div class=navbar-end><a class="navbar-item is-hidden-touch" href=https://www.linkedin.com/in/zmsyco><span class=icon><i class="fa fa-linkedin-square" title="View my LinkedIn profile."></i></span></a><a class="navbar-item is-hidden-touch" href=https://github.com/zmsy><span class=icon><i class="fa fa-github" title="Check out my Github."></i></span></a><a class="navbar-item is-hidden-touch" href=https://twitter.com/_zmsy><span class=icon><i class="fa fa-twitter" title="Check out my sparsely used Twitter account."></i></span></a><a class="navbar-item is-tab" href=https://zmsy.github.io/zmsy.co/>Home</a>
<a class="navbar-item is-tab" href=https://zmsy.github.io/zmsy.co/blog>Blog</a>
<a class="navbar-item is-tab" href=https://zmsy.github.io/zmsy.co/projects>Projects</a>
<a class="navbar-item is-tab" href=https://zmsy.github.io/zmsy.co/about>About</a></div></div></nav></div></div><div id=body><div class="columns is-centered is-desktop"><div class="column is-8 is-12-touch"><section class=section><div class=blog-post><h2><a class="title title-dark is-size-2-touch" href=https://zmsy.github.io/zmsy.co/blog/personal-data-engineering/>An Architecture For Personal Data Engineering</a></h2><p class=meta>written by
<a href=https://twitter.com/_zmsy>Zach Morrissey</a>
on 2019-03-26</p><img class=image id=hero-diamonds src=https://zmsy.github.io/zmsy.co/img/diamonds-dark.svg><div class=content><p>Performing in-depth data analyses on things in my own life have always been more difficult than in my working life, primarily because there I&rsquo;ve normally had teams of engineers who have helped in setting up and maintaining most of the analytics-focused infrastructure that I&rsquo;ve used. Supporting myself with the same sort of infrastructure I was used to was an adventure, <a href=https://zmsy.github.io/zmsy.co/blog/my-very-own-airflow-cluster/>one that started much earlier</a> and has since grown from there.</p><figure><img src=https://zmsy.github.io/zmsy.co/blog/personal-data-engineering/graphs.svg alt="Miscellaneous fake graphs for fun." class=no-border style=width:20rem;height:10rem></figure><h2 id=scope>Scope</h2><p>To most ends, downloading CSVs and plugging them into your spreadsheet software of choice will do most tasks well enough. For my purposes though, I wanted to scale this past what manual analysis was going to get me. There&rsquo;s a few key areas that I wanted this for:</p><ul><li>Personal finances. Most of the data that I create finds it&rsquo;s way into financial systems that are hard to get your information out of. I&rsquo;m not against the bank having my spending data, but I am frustrated that it&rsquo;s so hard for me to get it too.</li><li>Fantasy sports. I love sports and I love stats.</li><li>House shopping. This data is heaaaavily guarded and it&rsquo;s hard to find anything that isn&rsquo;t breaking some sort of ToS to get.</li></ul><p>This doesn&rsquo;t necessarily create a system that requires dedicated data engineering work, but some of the goals that I had for it did. These were:</p><ul><li><strong>Automated.</strong> I&rsquo;d like to see how repeatable and reproducible these analyses can be.</li><li><strong>Modeled.</strong> I&rsquo;d like to build and train some models related to how I live my life to see if there&rsquo;s any predictive benefit to these things.</li><li><strong>Interactive.</strong> - For everything that you see here, I&rsquo;d like to have some sort of interface that I can open, preferably via web browser.</li></ul><h2 id=the-bits-n-pieces>The Bits n' Pieces</h2><p>For doing this sort of work, I set up a few infrastructural components. Hardware is a low-spec server with <a href=https://www.proxmox.com/en/>Proxmox</a> (for VMs) and Docker/<a href=https://www.portainer.io/>Portainer</a>.</p><figure><img src=https://zmsy.github.io/zmsy.co/blog/personal-data-engineering/diagram.svg alt="Diagram of my personal data engineering architecture." class=no-border style=max-height:20rem></figure><ul><li><strong>Postgres database</strong> - My primary datastore. This is the hub of all activity that I do, serving as both an application backend / transactional database as well as an analytical database. Each are neatly separated out into different schemas. I use <a href=https://dbeaver.io/>DBeaver</a> as a SQL client for ad-hoc querying, manipulation, setup, etc. Since a single Postgres instance can scale to vastly larger workloads than I&rsquo;d ever be able to throw at it, this seemed like a good backbone for everything.</li><li><strong>Apache Airflow</strong> - In it&rsquo;s simplest form, I&rsquo;m using this basically as a scheduled job engine. Building on my <a href=%22/blog/my-very-own-airflow-cluster/%22>earlier post about Airflow</a>, I&rsquo;ve expanded my usage of it to a significant variety of different DAGs. This uses the same Postgres database as earlier.</li><li><strong>Jupyter Notebooks</strong> - Interactive analytical code/markdown files served up in your web browser. Jupyter is the ultimate tool in interactive analytical computing, with RStudio being the only major other option I considered (went with Jupyter, if for nothing else, because I find python more enjoyable to write). There&rsquo;s <a href=https://jupyterhub.readthedocs.io/en/stable/>great options</a> available if you want to run this on a server, I found that I like just running it locally the best.</li><li><strong>Apache Superset</strong> - Web-based Dashboards. <a href=https://superset.incubator.apache.org/installation.html#getting-started>Superset</a>, similar to Airflow, is based on Python/Flask and can be run in a single Docker container if you so desire. Since I need some way of sharing some of these results with a significant other (namely finance + house shopping data), I needed to have some sort of dashboarding software in order to have that visible to someone who will access it via web browser.</li></ul><h2 id=my-workflow>My Workflow</h2><p>Since the pieces have been set in place now, this is my general workflow:</p><figure><img src=https://zmsy.github.io/zmsy.co/blog/personal-data-engineering/process.svg alt="Process workflow from Airflow task to Jupyter notebook and then to Superset dashboard." class=no-border style=max-height:12rem></figure><ol><li>Find a new datasource. Generally, this is something scraped from the web or pulled from a service I use.</li><li>Write an Airflow task to pull that data on a regular schedule (normally nightly).</li><li>In Postgres, create schema / table in order to store info.</li><li>Use downstream in:<ol><li>Superset dashboard. This is normally when I&rsquo;ve created a datasource that I&rsquo;m interested in (i.e. personal spending data) and want to look at from a variety of angles.</li><li>Jupyter notebook. Normally, this is to either create a more in-depth analysis (any modelling required) or to investigate one hunch / idea that I&rsquo;ve got. In the event that I something useful to replicate, I ship this upstream into an Airflow task.</li><li>Exported to some sort of printable / shareable thing. Good example for this is pre-draft research for fantasy sports.</li></ol></li></ol><h2 id=tips>Tips</h2><p>This was a fun adventure to go on, but I&rsquo;m happy that it&rsquo;s stabilized by this point.</p><ul><li>It&rsquo;s fun stuff. It really is. Using data to analyze parts of your own life is something people rarely get to do.</li><li>There&rsquo;s a tradeoff between having a robust, feature-filled system and an easy one. As your needs change, your tools tend to change too. My aims for this outgrew my cron/jupyter/Google Sheets hackjob before trying to take on any of this.</li><li>Getting data is the hardest part. Significantly more time for me is spent writing data fetching tasks than anything else.</li></ul></div></div></section></div></div></div><footer class=footer><div class="container has-text-centered"><p id=footer-text><strong>zmsy.co</strong> - A personal blog by Zach Morrissey. Copyright Â© 2021</p><p><img class=footer-dots src=https://zmsy.github.io/zmsy.co/img/footer.svg alt="Five horizontal hand-drawn dots."></p></div></footer><script type=text/javascript src=https://zmsy.github.io/zmsy.co/ts/index.js></script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-104524581-1','auto'),ga('send','pageview'))</script><script async src=https://www.google-analytics.com/analytics.js></script></body></html>